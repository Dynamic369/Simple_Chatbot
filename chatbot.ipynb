{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04423c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='Gemma2-9b-It',api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ef48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Pradum and I am a Data Scientist.\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3537aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, I am Pradum and I am a Data Scientist.\"),\n",
    "        AIMessage(content=\"Hello Pradum! It's nice to meet you. \\n\\nAs a large language model, I'm always interested in learning more about people in different fields.\"),\n",
    "        HumanMessage(content=\"What is my name and what do i do?\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623d8ed",
   "metadata": {},
   "source": [
    "# Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a91516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{\"session_id\":'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a551560",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [HumanMessage(content='Hi, my name is Pradum and I am Data Scientist.')],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f105be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ff6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the config --> session id\n",
    "config1 = {'configurable':{'session_id':'chat2'}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47982e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content='Hey my name is Jhon')],\n",
    "    config = config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043de009",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"what's my name\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039c2e5",
   "metadata": {},
   "source": [
    "# Prompt Template\n",
    "it helps us to turn raw user information into a format that the llm can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa872a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",'you are a helpful assistant. Answer all the question to the nest of your ability.'),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content='Hi My name us Pradum')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbedf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history=get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat3'}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content='Hi my name is Pradum')],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content='What is my name')],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c47b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"You are a helpful assistant. Answer all the question to the best of your ability in {language}.\",\n",
    "\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='messages'),\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({'messages':[HumanMessage(content='Hi my name is Pradum')],'language':'Hindi'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873591a",
   "metadata": {},
   "source": [
    "Let's wrap this more complicated chain in a message history class. this time, because there are multiple keys in the input, we need to specify the correct key to save the hcat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='messages'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1615214",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat4'}}\n",
    "response = with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi I am Pradum\")],'language':'Hindi'},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e94cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d67b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke({'messages':[HumanMessage(content='What is my name?')],'language':'Hindi'},\n",
    "                                       config=config\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b53db6",
   "metadata": {},
   "source": [
    "# Managing the conversation History\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13180320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens =45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    "\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b919b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content='what ice cream do i like')],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"messages\":messages + [HumanMessage(content='What math problem is gave')],\"language\":\"English\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047bffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets wrap this is message history.\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1906186",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What's is my name\")],\n",
    "        \"language\":\"english\"\n",
    "    },\n",
    "    config= config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9435af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What problen did i ask\")],\n",
    "        \"language\":\"english\"\n",
    "    },\n",
    "    config= config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9629b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
